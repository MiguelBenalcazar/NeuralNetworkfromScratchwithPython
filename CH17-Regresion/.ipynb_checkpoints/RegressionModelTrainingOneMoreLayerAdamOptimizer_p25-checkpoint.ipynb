{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "from nnfs.datasets import sine_data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons,weight_regularizer_l1=0, weight_regularizer_l2=0,bias_regularizer_l1=0, bias_regularizer_l2=0):\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "        # Set regularization strength\n",
    "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
    "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
    "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
    "        self.bias_regularizer_l2 = bias_regularizer_l2\n",
    "        \n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "        \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradients on regularization\n",
    "        # L1 on weights\n",
    "        if self.weight_regularizer_l1 > 0:\n",
    "            dL1 = np.ones_like(self.weights)\n",
    "            dL1[self.weights < 0] = -1\n",
    "            self.dweights += self.weight_regularizer_l1 * dL1\n",
    "    \n",
    "        # L2 on weights\n",
    "        if self.weight_regularizer_l2 > 0:\n",
    "            self.dweights += 2 * self.weight_regularizer_l2 * self.weights\n",
    "        \n",
    "        # L1 on biases\n",
    "        if self.bias_regularizer_l1 > 0:\n",
    "            dL1 = np.ones_like(self.biases)\n",
    "            dL1[self.biases < 0] = -1\n",
    "            self.dbiases += self.bias_regularizer_l1 * dL1\n",
    "    \n",
    "        # L2 on biases\n",
    "        if self.bias_regularizer_l2 > 0:\n",
    "            self.dbiases += 2 * self.bias_regularizer_l2 * self.biases\n",
    "        \n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "    # Forward pass\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify original variable,\n",
    "        # let's make a copy of values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Zero gradient where input values were negative\n",
    "        self.dinputs[self.inputs <= 0] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "    # Forward pass\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,keepdims=True)\n",
    "        self.output = probabilities\n",
    "        \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            # Calculate Jacobian matrix of the output and\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "            # Calculate sample-wise gradient\n",
    "            # and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,single_dvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation\n",
    "class Activation_Sigmoid:\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Save input and calculate/save output\n",
    "        # of the sigmoid function\n",
    "        self.inputs = inputs\n",
    "        self.output = 1 / (1 + np.exp(-inputs))\n",
    "        \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Derivative - calculates from output of the sigmoid function\n",
    "        self.dinputs = dvalues * (1 - self.output) * self.output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Linear:\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Just remember values\n",
    "        self.inputs = inputs\n",
    "        self.output = inputs\n",
    "        \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "       # derivative is 1, 1 * dvalues = dvalues - the chain rule\n",
    "        self.dinputs = dvalues.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Optimizer_SGD:\n",
    "    \n",
    "    # Initialize optimizer - set settings,\n",
    "    # learning rate of 1. is default for this optimizer\n",
    "    \n",
    "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "            \n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        # If we use momentum\n",
    "        if self.momentum:\n",
    "            # If layer does not contain momentum arrays, create them\n",
    "            # filled with zeros\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                # If there is no momentum array for weights\n",
    "                # The array doesn't exist for biases yet either.\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "\n",
    "            # Build weight updates with momentum - take previous\n",
    "            # updates multiplied by retain factor and update with\n",
    "            # current gradients\n",
    "            weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "            \n",
    "            # Build bias updates\n",
    "            bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "            \n",
    "        # Vanilla SGD updates (as before momentum update)\n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate * layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * layer.dbiases\n",
    "            \n",
    "        # Update weights and biases using either\n",
    "        # vanilla or momentum updates\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "        \n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adagrad optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_Adagrad:\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__(self, learning_rate=1., decay=0., epsilon=1e-7):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # Call once before any parameter update\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "        \n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache += layer.dweights**2\n",
    "        layer.bias_cache += layer.dbiases**2\n",
    "        \n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "            \n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_RMSprop:\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,rho=0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.rho = rho\n",
    "        \n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "            \n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "        \n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache = self.rho * layer.weight_cache + (1 - self.rho) * layer.dweights**2\n",
    "        layer.bias_cache = self.rho * layer.bias_cache + (1 - self.rho) * layer.dbiases**2\n",
    "\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "        \n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_Adam:\n",
    "    # Initialize optimizer - set settings\n",
    "    \n",
    "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,beta_1=0.9, beta_2=0.999):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "    \n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "            \n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "            \n",
    "        # Update momentum with current gradients\n",
    "        layer.weight_momentums = self.beta_1 * layer.weight_momentums + (1 - self.beta_1) * layer.dweights\n",
    "        layer.bias_momentums = self.beta_1 * layer.bias_momentums + (1 - self.beta_1) * layer.dbiases\n",
    "            \n",
    "        # Get corrected momentum\n",
    "        # self.iteration is 0 at first pass\n",
    "        # and we need to start with 1 here\n",
    "        weight_momentums_corrected = layer.weight_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
    "        bias_momentums_corrected = layer.bias_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache = self.beta_2 * layer.weight_cache + (1 - self.beta_2) * layer.dweights**2\n",
    "        layer.bias_cache = self.beta_2 * layer.bias_cache + (1 - self.beta_2) * layer.dbiases**2\n",
    "        \n",
    "        # Get corrected cache\n",
    "        weight_cache_corrected = layer.weight_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
    "        bias_cache_corrected = layer.bias_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
    "        \n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * weight_momentums_corrected / (np.sqrt(weight_cache_corrected) +self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * bias_momentums_corrected / (np.sqrt(bias_cache_corrected) +self.epsilon)\n",
    "        \n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common loss class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common loss class\n",
    "class Loss:\n",
    "    # Regularization loss calculation\n",
    "    \n",
    "    def regularization_loss(self, layer):\n",
    "        # 0 by default\n",
    "        regularization_loss = 0\n",
    "        \n",
    "        # L1 regularization - weights\n",
    "        # calculate only when factor greater than 0\n",
    "        \n",
    "        \n",
    "        if layer.weight_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.weight_regularizer_l1 * np.sum(np.abs(layer.weights))\n",
    "            \n",
    "        # L2 regularization - weights\n",
    "        if layer.weight_regularizer_l2 > 0:\n",
    "            regularization_loss += layer.weight_regularizer_l2 * np.sum(layer.weights * layer.weights)\n",
    "\n",
    "        # L1 regularization - biases\n",
    "        # calculate only when factor greater than 0\n",
    "            \n",
    "        if layer.bias_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.bias_regularizer_l1 * np.sum(np.abs(layer.biases))\n",
    "            \n",
    "            # L2 regularization - biases\n",
    "            if layer.bias_regularizer_l2 > 0:\n",
    "                regularization_loss += layer.bias_regularizer_l2 * np.sum(layer.biases * layer.biases)\n",
    "        \n",
    "        return regularization_loss\n",
    "    \n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self, output, y):\n",
    "        \n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "        \n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        # Return loss\n",
    "        \n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        \n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples),y_true]\n",
    "            \n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true,axis=1)\n",
    "            \n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_BinaryCrossentropy(Loss):\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        # Calculate sample-wise loss\n",
    "        sample_losses = -(y_true * np.log(y_pred_clipped) + (1 - y_true) * np.log(1 - y_pred_clipped))\n",
    "        sample_losses = np.mean(sample_losses, axis=-1)\n",
    "        # Return losses\n",
    "        return sample_losses\n",
    "    \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of outputs in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        outputs = len(dvalues[0])\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        clipped_dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -(y_true / clipped_dvalues -(1 - y_true) / (1 - clipped_dvalues)) / outputs\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, dvalues, y_true):\n",
    "    # Number of samples\n",
    "    samples = len(dvalues)\n",
    "    # Number of labels in every sample\n",
    "    # We'll use the first sample to count them\n",
    "    labels = len(dvalues[0])\n",
    "    # If labels are sparse, turn them into one-hot vector\n",
    "    if len(y_true.shape) == 1:\n",
    "        y_true = np.eye(labels)[y_true]\n",
    "        \n",
    "    # Calculate gradient\n",
    "    self.dinputs = -y_true / dvalues\n",
    "    # Normalize gradient\n",
    "    self.dinputs = self.dinputs / samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax classifier - combined Softmax activation\n",
    "# and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "    # Creates activation and loss function objects\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "    \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "        \n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # If labels are one-hot encoded,\n",
    "        # turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "            \n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "        \n",
    "        # Calculate gradient\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        \n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout\n",
    "class Layer_Dropout:\n",
    "    \n",
    "    # Init\n",
    "    def __init__(self, rate):\n",
    "        # Store rate, we invert it as for example for dropout\n",
    "        # of 0.1 we need success rate of 0.9\n",
    "        self.rate = 1 - rate\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Save input values\n",
    "        self.inputs = inputs\n",
    "        # Generate and save scaled mask\n",
    "        self.binary_mask = np.random.binomial(1, self.rate,size=inputs.shape) / self.rate\n",
    "        # Apply mask to output values\n",
    "        self.output = inputs * self.binary_mask\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradient on values\n",
    "        self.dinputs = dvalues * self.binary_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_MeanAbsoluteError(Loss): # L1 loss\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Calculate loss\n",
    "        sample_losses = np.mean(np.abs(y_true - y_pred), axis=-1)\n",
    "        # Return losses\n",
    "        return sample_losses\n",
    "    \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of outputs in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        outputs = len(dvalues[0])\n",
    "        \n",
    "        # Calculate gradient\n",
    "        self.dinputs = np.sign(y_true - dvalues) / outputs\n",
    "        \n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_MeanSquaredError(Loss): # L2 loss\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Calculate loss\n",
    "        sample_losses = np.mean((y_true - y_pred)**2, axis=-1)\n",
    "        # Return losses\n",
    "        return sample_losses\n",
    "    \n",
    "    # Backward pas\n",
    "    def backward(self, dvalues, y_true):\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        \n",
    "        # Number of outputs in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        outputs = len(dvalues[0])\n",
    "        \n",
    "        # Gradient on values\n",
    "        self.dinputs = -2 * (y_true - dvalues) / outputs\n",
    "        \n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.002, loss: 0.500 (data_loss: 0.500, reg_loss: 0.000), lr: 0.01\n",
      "epoch: 100, acc: 0.027, loss: 0.061 (data_loss: 0.061, reg_loss: 0.000), lr: 0.009099181073703368\n",
      "epoch: 200, acc: 0.080, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.008340283569641367\n",
      "epoch: 300, acc: 0.026, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.007698229407236336\n",
      "epoch: 400, acc: 0.295, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.007147962830593281\n",
      "epoch: 500, acc: 0.405, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0066711140760507\n",
      "epoch: 600, acc: 0.045, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.006253908692933083\n",
      "epoch: 700, acc: 0.309, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.005885815185403178\n",
      "epoch: 800, acc: 0.370, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.005558643690939411\n",
      "epoch: 900, acc: 0.392, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0052659294365455505\n",
      "epoch: 1000, acc: 0.384, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.005002501250625312\n",
      "epoch: 1100, acc: 0.450, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.004764173415912339\n",
      "epoch: 1200, acc: 0.034, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.004547521600727604\n",
      "epoch: 1300, acc: 0.409, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.004349717268377556\n",
      "epoch: 1400, acc: 0.411, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.004168403501458941\n",
      "epoch: 1500, acc: 0.448, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.004001600640256103\n",
      "epoch: 1600, acc: 0.412, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.003847633705271258\n",
      "epoch: 1700, acc: 0.128, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.003705075954057058\n",
      "epoch: 1800, acc: 0.267, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.003572704537334763\n",
      "epoch: 1900, acc: 0.118, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0034494653328734047\n",
      "epoch: 2000, acc: 0.456, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.003334444814938313\n",
      "epoch: 2100, acc: 0.453, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0032268473701193936\n",
      "epoch: 2200, acc: 0.453, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0031259768677711786\n",
      "epoch: 2300, acc: 0.389, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0030312215822976664\n",
      "epoch: 2400, acc: 0.456, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0029420417769932335\n",
      "epoch: 2500, acc: 0.456, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0028579594169762792\n",
      "epoch: 2600, acc: 0.456, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.002778549597110308\n",
      "epoch: 2700, acc: 0.463, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.002703433360367667\n",
      "epoch: 2800, acc: 0.462, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0026322716504343247\n",
      "epoch: 2900, acc: 0.461, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0025647601949217746\n",
      "epoch: 3000, acc: 0.122, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0025006251562890726\n",
      "epoch: 3100, acc: 0.452, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0024396194193705783\n",
      "epoch: 3200, acc: 0.468, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0023815194093831865\n",
      "epoch: 3300, acc: 0.469, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0023261223540358227\n",
      "epoch: 3400, acc: 0.456, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0022732439190725168\n",
      "epoch: 3500, acc: 0.332, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.002222716159146477\n",
      "epoch: 3600, acc: 0.458, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0021743857360295715\n",
      "epoch: 3700, acc: 0.476, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0021281123643328366\n",
      "epoch: 3800, acc: 0.477, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.002083767451552407\n",
      "epoch: 3900, acc: 0.479, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0020412329046744235\n",
      "epoch: 4000, acc: 0.476, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0020004000800160028\n",
      "epoch: 4100, acc: 0.462, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0019611688566385566\n",
      "epoch: 4200, acc: 0.317, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0019234468166955186\n",
      "epoch: 4300, acc: 0.483, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0018871485185884126\n",
      "epoch: 4400, acc: 0.488, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0018521948508983144\n",
      "epoch: 4500, acc: 0.491, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0018185124568103291\n",
      "epoch: 4600, acc: 0.495, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.001786033220217896\n",
      "epoch: 4700, acc: 0.489, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.001754693805930865\n",
      "epoch: 4800, acc: 0.238, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.001724435247456458\n",
      "epoch: 4900, acc: 0.482, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0016952025767079165\n",
      "epoch: 5000, acc: 0.502, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0016669444907484582\n",
      "epoch: 5100, acc: 0.498, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0016396130513198885\n",
      "epoch: 5200, acc: 0.499, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0016131634134537829\n",
      "epoch: 5300, acc: 0.493, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0015875535799333227\n",
      "epoch: 5400, acc: 0.199, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0015627441787779339\n",
      "epoch: 5500, acc: 0.488, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0015386982612709647\n",
      "epoch: 5600, acc: 0.514, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0015153811183512653\n",
      "epoch: 5700, acc: 0.502, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0014927601134497688\n",
      "epoch: 5800, acc: 0.515, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0014708045300779527\n",
      "epoch: 5900, acc: 0.493, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0014494854326714017\n",
      "epoch: 6000, acc: 0.514, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.001428775539362766\n",
      "epoch: 6100, acc: 0.509, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0014086491055078179\n",
      "epoch: 6200, acc: 0.537, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0013890818169190167\n",
      "epoch: 6300, acc: 0.520, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0013700506918755992\n",
      "epoch: 6400, acc: 0.518, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0013515339910798758\n",
      "epoch: 6500, acc: 0.518, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0013335111348179757\n",
      "epoch: 6600, acc: 0.351, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0013159626266614028\n",
      "epoch: 6700, acc: 0.496, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0012988699831146902\n",
      "epoch: 6800, acc: 0.532, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0012822156686754713\n",
      "epoch: 6900, acc: 0.395, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.00126598303582732\n",
      "epoch: 7000, acc: 0.423, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0012501562695336915\n",
      "epoch: 7100, acc: 0.541, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0012347203358439314\n",
      "epoch: 7200, acc: 0.537, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0012196609342602757\n",
      "epoch: 7300, acc: 0.501, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0012049644535486203\n",
      "epoch: 7400, acc: 0.504, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0011906179307060363\n",
      "epoch: 7500, acc: 0.291, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.001176609012825038\n",
      "epoch: 7600, acc: 0.277, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.001162925921618793\n",
      "epoch: 7700, acc: 0.532, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0011495574203931487\n",
      "epoch: 7800, acc: 0.517, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0011364927832708263\n",
      "epoch: 7900, acc: 0.486, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.001123721766490617\n",
      "epoch: 8000, acc: 0.479, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.00111123458162018\n",
      "epoch: 8100, acc: 0.552, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0010990218705352237\n",
      "epoch: 8200, acc: 0.557, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0010870746820306556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8300, acc: 0.560, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0010753844499408539\n",
      "epoch: 8400, acc: 0.528, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0010639429726566655\n",
      "epoch: 8500, acc: 0.585, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0010527423939362037\n",
      "epoch: 8600, acc: 0.556, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0010417751849150952\n",
      "epoch: 8700, acc: 0.563, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0010310341272296113\n",
      "epoch: 8800, acc: 0.551, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.001020512297173181\n",
      "epoch: 8900, acc: 0.419, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0010102030508132135\n",
      "epoch: 9000, acc: 0.503, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.001000100010001\n",
      "epoch: 9100, acc: 0.570, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0009901970492127933\n",
      "epoch: 9200, acc: 0.546, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0009804882831650162\n",
      "epoch: 9300, acc: 0.567, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0009709680551509856\n",
      "epoch: 9400, acc: 0.528, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0009616309260505818\n",
      "epoch: 9500, acc: 0.551, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0009524716639679969\n",
      "epoch: 9600, acc: 0.497, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0009434852344560807\n",
      "epoch: 9700, acc: 0.593, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0009346667912889055\n",
      "epoch: 9800, acc: 0.546, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0009260116677470137\n",
      "epoch: 9900, acc: 0.565, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0009175153683824203\n",
      "epoch: 10000, acc: 0.564, loss: 0.031 (data_loss: 0.031, reg_loss: 0.000), lr: 0.0009091735612328393\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset\n",
    "X, y = sine_data()\n",
    "\n",
    "# Create Dense layer with 1 input feature and 64 output values\n",
    "dense1 = Layer_Dense(1, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 1 output value\n",
    "dense2 = Layer_Dense(64, 64)\n",
    "\n",
    "# Create Linear activation:\n",
    "activation2 = Activation_ReLU()\n",
    "\n",
    "# Create third Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 1 output value\n",
    "dense3 = Layer_Dense(64, 1)\n",
    "\n",
    "# Create Linear activation:\n",
    "activation3 = Activation_Linear()\n",
    "\n",
    "# Create loss function\n",
    "loss_function = Loss_MeanSquaredError()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_Adam(learning_rate=0.01, decay=1e-3)\n",
    "\n",
    "# Accuracy precision for accuracy calculation\n",
    "# There are no really accuracy factor for regression problem,\n",
    "# but we can simulate/approximate it. We'll calculate it by checking\n",
    "# how many values have a difference to their ground truth equivalent\n",
    "# less than given precision\n",
    "# We'll calculate this precision as a fraction of standard deviation\n",
    "# of al the ground truth values\n",
    "accuracy_precision = np.std(y) / 250\n",
    "\n",
    "loss_acum = []\n",
    "accuracy_acum = []\n",
    "count = []\n",
    "y_hat = []\n",
    "\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "    \n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "    \n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function\n",
    "    # of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "    \n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of second dense layer here\n",
    "    activation2.forward(dense2.output)\n",
    "    \n",
    "    # Perform a forward pass through third Dense layer\n",
    "    # takes outputs of activation function of second layer as inputs\n",
    "    dense3.forward(activation2.output)\n",
    "    \n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of third dense layer here\n",
    "    activation3.forward(dense3.output)\n",
    "    \n",
    "    # Calculate the data loss\n",
    "    data_loss = loss_function.calculate(activation3.output, y)\n",
    "    \n",
    "    # Calculate regularization penalty\n",
    "    regularization_loss = loss_function.regularization_loss(dense1) + loss_function.regularization_loss(dense2)+ loss_function.regularization_loss(dense3)\n",
    "\n",
    "    # Calculate overall loss\n",
    "    loss = data_loss + regularization_loss\n",
    "    \n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # To calculate it we're taking absolute difference between\n",
    "    # predictions and ground truth values and compare if differences\n",
    "    # are lower than given precision value\n",
    "    \n",
    "    predictions = activation3.output\n",
    "    accuracy = np.mean(np.absolute(predictions - y) < accuracy_precision)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {accuracy:.3f}, ' +\n",
    "              f'loss: {loss:.3f} (' +\n",
    "              f'data_loss: {data_loss:.3f}, ' +\n",
    "              f'reg_loss: {regularization_loss:.3f}), ' +\n",
    "              f'lr: {optimizer.current_learning_rate}')\n",
    "        \n",
    "    loss_acum.append(loss)\n",
    "    accuracy_acum.append(accuracy)\n",
    "    y_hat = predictions\n",
    "    count.append(epoch)\n",
    "        \n",
    "    \n",
    "    # Backward pass\n",
    "    loss_function.backward(activation3.output, y)\n",
    "    activation3.backward(loss_function.dinputs)\n",
    "    dense3.backward(activation3.dinputs)\n",
    "    activation2.backward(dense3.dinputs)\n",
    "    dense2.backward(activation2.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    \n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.update_params(dense3)\n",
    "    optimizer.post_update_params()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test, y_test = sine_data()\n",
    "\n",
    "dense1.forward(X_test)\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "dense3.forward(activation2.output)\n",
    "activation3.forward(dense3.output)\n",
    "plt.plot(X_test, y_test)\n",
    "plt.plot(X_test, activation3.output)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(y=accuracy_acum , x=count)\n",
    "sns.lineplot(y=loss_acum, x=count)\n",
    "# plt.ylim(0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
